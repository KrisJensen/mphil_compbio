
#Code for doing FGA1. This generates and saves all necessary figures
#and prints some useful information.

save_plots = 0 #set to 1 if you want to save plots instead of displaying them
run_large_JKscreen = 0  #set to 1 if you want to quantify the effect of J and K over 1000 repetitions
			#rather than just running one example (runs 5000 simulations so takes ~10 minutes)

###First we define all of the necessary functions

simulate.data = function(a1, b1, a2, b2, J, K){
  #Generate a list of reads for a single gene assuming two labs,
  #J cell lines each, K replicates. Returns vector of reads.
  return(rpois(2*J*K, rep(rgamma(2*J, rep(c(a1, a2), each=J),
              rate = rep(c(b1, b2), each = J)), each = K))) 
}

plot_reads = function(J=10, K=10, save=0){
  #generates a sequence of reads for J cell lines,
  #K replicates and plots this read vector
  reads = simulate.data(100, 2, 100, 3, J, K) #get reads
  if (save){pdf('counts_plot.pdf')}
  par(mfrow=c(1,1))
  plot(1:200, reads, pch = rep(c(16, 17), each=100), col=rep(rainbow(10), each = 10),
       cex = 0.8, xlab = 'Index', ylab = 'Reads', main = 'Randomly generated reads' )
  if (save){dev.off()}
}

many_plots = function(n = 10, xlim = 800, save=0){
  #plots n^2 poisson distributions with lambda generated by gamma functions
  #as specified in the assignment. xrange = [0, xlim]
  if (save){pdf(file = 'many_plots.pdf')}
  par(mfrow=c(n,n), mar = c(0.2, 0.2, 0.2, 0.2))
  
  b = rgamma(n^2, 0.5, rate=0.1) #generate betas
  l = rgamma(n^2, 100, rate=b) #generate lambdas
  m = min(ceiling(1.25*max(l)), 800) #find max x value
  cat('\nmax l', max(l), '\n\n')
  k = seq(0, m, ceiling(m/1000)) #generate x vector
  
  for (i in 1:n^2){
    yvals = dpois(k, l[i]) #find poisson(x; lambda) for each x
    plot(k, yvals, 'l', xlim=c(0, max(k)), ylim = c(0, max(yvals+0.02)),
      xlab = '', ylab = '', xaxt='n', yaxt='n')}
  if (save){dev.off()}
}


gibbs.sampler = function(reads, init, J = 10, K = 10, N=10000){
  #samples N iterations of betas and lambdas from equations 5 and 6 in the assignment
  #reads is a vector of reads in the form outputted by simulate.data()
  #init = c(b1, b2) specify initial beta values. Returns list of lambdas, betas.
  a = 0.5; b = 0.1
  #initialize vectors for storing data
  ls_t = matrix(, 2*J, N); bs_t = matrix(, 2, N ); bs_t[,1] = bs = init
  reads = colSums(matrix(reads, K, 2*J)) #get vector of reads summed across experiments
  
  for (t in 2:N){
    ls = rgamma( 2*J, 100+reads, rate = (rep(bs, each = J)+K) ) #update all lambdas
    bs = rgamma( 2, a + c(100,100)*J, rate = (b+colSums(matrix(ls, J, 2))) ) #update all betas
    ls_t[,t] = ls; bs_t[,t]=bs #store values
  }
  return( list('lambda'=ls_t, 'beta'=bs_t) )
}

rolling = function(x, n=100){
  #returns list of rolling average and standard deviation of the input vector.
  N = length(x); means=sds=numeric(N)
  #for first n entries, do average with all previous values
  for (i in 1:n){means[i] = mean(x[1:i]); sds[i] = sd(x[1:i])}; sds[1]=0 
  for (i in (n+1):N){means[i] = mean(x[(i-(n-1)):i]); sds[i] = sd(x[(i-(n-1)):i])} #rolling average
  return( list(means, sds) )
}

run_sim = function(J, K, N = 2000, a1=100, b1 = 0.12,
                   a2 = 100, b2 = 0.1, print=1, init = c(0.15, 0.12)){
  #function for generating reads and running gibbs.sampler given parameters.
  #Returns list of lambdas, betas.
  reads = simulate.data(a1, b1, a2, b2, J, K)
  res = gibbs.sampler(reads, init=init, J=J, K=K, N=N) #run gibbs sampler
  #test if means of posterior beta distributions differ
  t = t.test(a1/res[[2]][1,-(1:100)]-a2/res[[2]][2,-(1:100)], alternative='l')
  if (print){ cat('\n\nJ =',J,'K =',K, 'p_same =', t$p.value, 'conf', t$conf.int[1:2])
              print(t) } #print t-test result and a brief summary
  return(res)
}
  
plot_traces = function(bs, bs_exact = c(0.12, 0.10), main = 'test', save=0){
  #given the posterior values of an MCMC chain (bs), plots MCMC traces for beta values
  #bs_exact specifies the true beta values used to draw the reads
  N = dim(bs)[2]
  if (save){pdf(paste0(main, '_traces.pdf'))}
  par(mfrow=c(2,1),mar=c(4,4,2,1))
  for (i in 1:2){ #plot both beta1 and beta2; formatting identical so write as loop
    plot(1:N, bs[i,], 'l', xlab='Iteration', ylab='beta', main=paste('MCMC trace lab', i))
    roll = rolling( bs[i,], n=100 ) #get rolling average
    means = roll[[1]]; m_msd = roll[[1]] - roll[[2]]; m_psd = roll[[1]] + roll[[2]]
    polygon(c(2:N, N:2), y = c(m_msd[-1], m_psd[N:2]), col=rgb(0, 1, 0,0.3), border=NA) #shade mean +- sd
    lines(2:N, means[-1], col='green') #plot mean
    lines(1:N, rep(bs_exact[i], N), col='red') #plot true beta values
  }
  if (save){dev.off()}
}
  
plot_hist = function(bs, main = 'test', a1=100, a2=100, save=0){
  #given the posterior beta values of an MCMC chain (bs), plots a histogram of
  #differences in posterior means.
  if (save){pdf(paste0(main, '_hist_diff.pdf'))}
  #calulate difference in posterior means at each iteration after burn-in
  meandiff = (a1/bs[1,-(1:100)]-a2/bs[2,-(1:100)]) 
  #get parameters for a normal distribution
  m = mean(meandiff); sd = sd(meandiff); xs = seq(min(meandiff), max(meandiff), length=1000)
  par(mfrow=c(1,1))
  h = hist(meandiff, breaks=20, xlab = 'Mean lab 1 minus mean lab 2',
       ylab = 'Frequency', main = 'Distribution of differences in posterior mean')
  #plot histogram and overlay normal distribution
  lines(xs, dnorm(xs, mean = m, sd=sd)*length(meandiff)*diff(h$mids[1:2]), col='blue', lwd=1.5, lty = 2 )
  print(shapiro.test(meandiff)) #confirm that data is normally distributed using Shapiro-Wilks test
  if (save){dev.off()}
}

plot_distribution = function(bs, bs_exact=c(0.12,0.10)){
  #given the posterior beta values of an MCMC chain (bs),
  #plots distribution of these after burn-in
  #bs_exact specifies the true beta values used to draw the reads
  d1 = density( bs[1,-(1:100)] ) #we have many values so plot as smooth density
  d2 = density( bs[2,-(1:100)] ) 
  plot( d2, xlim = c(0.085, 0.135), col = 'red',
        main = paste0('J=',J,' K=',K), xlab = 'beta', ylab='Probability' )
  lines( d1, col='blue' )
  abline(v = bs_exact, lty=2) #add vertical lines at exact values
}

##############    Now we run some actual code   #################

plot_reads(save = save_plots) #generate vector of reads for J=K=10 and plot these
many_plots( n = 10, save = save_plots )  #plot 100 Poisson distributions

N = 5000 #number of iterations for gibbs.sampler
init = c(0.15, 0.12) #also converges for higher values but this gives nice plots
bs = run_sim(10, 10, N=N, init=init)[[2]] #run MCMC simulation
plot_traces(bs, main='MCMC', save = save_plots)
plot_hist(bs, main='MCMC', save = save_plots)

#investigate effect of J and K on posterior distribution
if (save_plots){pdf('screen_distributions.pdf', width = 9, height = 6)}
par(mfrow=c(2,2), mar = c(2.5, 2.5, 2.5, 2.5) )
for (K in c(10,100)){ 
  for (J in c(10,100)){
    if (J == 10 & K ==10){plot_distribution(bs) # no need to run this again, reuse data
    } else {bs = run_sim(J, K, N = N, init=init)[[2]]; plot_distribution(bs)}
  }
}
if (save_plots){dev.off()}



##### run an additional test comparing different J and K values ####
#this takes a bit of time so the function call (line 219) is conditional. Change settings in beginning of script.

test_JK = function(Nsims= 1000){
  #run Nsims MCMC simulations and store posterior means and sds
  #Do this for (J, K) pairs specified by 'params'
  #return list of summary mean/sd of means and standard deviations, and mean/sd per iteration
  cat('\nBeginning screen of the effect of J and K with', Nsims, 'simulations\n')
  params = list( c(10,2), c(10,10), c(10,100), c(100,10), c(100,100))
  results = list()
  summary = vector('list', 4) #means and sds over simulations
  for (param in 1:5){
    J = params[[param]][1]; K = params[[param]][2]
    ms = matrix(,2,Nsims) #initialize matrix of means and sds for each simulation
    sds = matrix(,2,Nsims)
    for (i in 1:Nsims){
      if (i %% 100 == 0){cat('\n J =', J, 'K =', K, 'i =', i, '\n')}
      bs = run_sim(J, K, N = N, print=0, init=init)[[2]] #run simulation
      bs = bs[,100:dim(bs)[2]] #remove burn-in
      ms[,i] = rowMeans(bs) #store mean of posterior betas
      sds[,i] = apply(bs, 1, sd) #store sd of posterior betas
    }
    results[[param]] = list(ms, sds) #store results of all simulations
    
    #calculate summary statistics
    summary[[1]] = cbind(summary[[1]], apply(ms, 1, mean)) #mean of mean posterior beta values
    summary[[2]] = cbind(summary[[2]], apply(ms, 1, sd)) #sd of mean posterior beta values
    summary[[3]] = cbind(summary[[3]], apply(sds, 1, mean)) #mean of sd of posterior beta values
    summary[[4]] = cbind(summary[[4]], apply(sds, 1, sd)) #sd of sd of posterior beta values
  }
  return( list(summary, results) )
}

plot_screen = function(summ){
  if (save_plots){pdf('repeat_screen.pdf', width = 6, height = 6)}
  par(mfrow=c(2,1), mar = c(2.5, 2.5, 2.5, 2.5) )
  mains = c('Means', '', 'Standard Devations')
  for (i in c(1,3)){ #plot barplots of means and standard deviations. Formatting identical so run as loop.
    barCenters <- barplot(height = summ[[i]][1,], #plot bars
                          names.arg = c('J=10 K=2','J=10 K=10','J=10 K=100','J=100 K=10','J=100 K=100'),
                          main = mains[i], border = "black", col = 'blue', xpd=0, cex.names=0.8,
                          ylim = c(0.8*min(summ[[i]][1,]), 1.2*max(summ[[i]][1,])) )
    #plot error bars
    segments(barCenters, summ[[i]][1,] - summ[[i+1]][1,], barCenters,
             summ[[i]][1,] + summ[[i+1]][1,], lwd = 3.5)
    arrows(barCenters, summ[[i]][1,] - summ[[i+1]][1,], barCenters,
           summ[[i]][1,] + summ[[i+1]][1,], lwd = 3.5, angle = 90,
           code = 3, length = 0.05)
  }
  if (save_plots){dev.off()}
  
  sds = res[[1]][[3]]
  change = c(sds[1,2]/sds[1,4], sds[1,3]/sds[1,5], sds[2,2]/sds[2,4], sds[2,3]/sds[2,5])
  cat('\nFold change in standard deviation from J=100 to 10 is', round(mean(change), 3))
  cat('\nThis is', round((mean(change)-sqrt(10))/sqrt(10)*100, 4), '% from sqrt(10)')
  cat('\nChange in standard deviation from K=10 to 2 is',
      round(mean(c((sds[1,1]-sds[1,2])/sds[1,2], (sds[2,1]-sds[2,2])/sds[2.2])*100), 2), '%\n' )
}


#Run simulations; this takes a while so have left it conditional
if (run_large_JKscreen){ res = test_JK(1000); summ = res[[1]]; plot_screen(summ) }


